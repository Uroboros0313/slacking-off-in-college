# Variational AutoEncoder

## AE的问题

对于训练集, 解码器能无损失地重建形状。如果我们对解码器输入一个训练集中没有出现过的编码, 解码器如果解码不出原本的形状, 说明AE是过拟合的。

## VAE

VAE和标准的自动编码器一样由编码器和解码器组成, 训练使**编码解码数据和初始数据之间的重建误差最小化**。

不同的是, 为了正则化, 不将输入数据编码成单个点, 而是**将输入数据编码成编码空间上的分布**。如果说自动编码器通过训练数据学习到的是某个确定的函数, 那么VAE希望能够基于训练数据学习到参数的概率分布。

- **训练**:

1. 输入数据被编码成编码空间上的分布。
2. 从**编码空间**中采样出一个点
3. 对采样点进行解码, 计算重建误差
4. 重建误差通过网络反向传播

- 编码分布: **正态分布(高斯分布)**。    
- 最小化损失函数: 由一个**重构项和一个正则化项**组成。
  - 通过使编码器返回的分布接近标准正态分布来规范潜在空间的组织。
  - 该正则化项表示为返回分布与标准高斯分布之间的Kulback-Leibler散度(KL divergence)。
    >KL散度也叫相对熵,其理论意义在于度量两个概率分布之间的差异程度，KL散度越高说明两个分布之间的差异程度越大，如果两个分布相同则KL散度为0。
  - 编码空间的规律性主要通过两个属性表达:
    1. 连续性(编码空间中相近的两个点一旦解码不应给出两个完全不同的内容)
    2. 完整性(对于选定的分布, 从编码空间中采样得到的点在解码后应给出有意义的内容)。

> 注意: VAE并不假设概率分布是一个高斯分布, 而是假设通过encoder将输入概率空间转化为一个概率分布——即条件概率分布


REF:
1. https://zhuanlan.zhihu.com/p/76509212?from_voters_page=true
2. https://zhuanlan.zhihu.com/p/433162159
3. https://blog.csdn.net/cloudless_sky/article/details/123697481